{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac26811",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7013165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe348b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0aa39",
   "metadata": {},
   "source": [
    "# Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/Users/mnoor/Desktop/FaceMaskProject/FaceMask/img'\n",
    "CATEGORIES = ['with_mask','without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "IMG_SIZE=128\n",
    "def making_trian_dataset():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(data_path, category) # path to our data\n",
    "        class_num = CATEGORIES.index(category)# classifcation index\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) # resizing our imgz\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "making_trian_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "train_data, labels_data = zip(*training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sample in training_data[:10]:\n",
    "    print(Sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf237df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X = np.array(X)#.reshape(-1, IMG_SIZE,IMG_SIZE,3)\n",
    "y = to_categorical(y, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d514da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038b423",
   "metadata": {},
   "source": [
    "Data Splitting For Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsample,nx,ny,ni=X.shape\n",
    "X1=X.reshape(nsample,nx*ny*ni)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_val_test, y1_train, y1_val_test = train_test_split(X1, y, test_size=.2, random_state=77)\n",
    "X1_val, X1_test, y1_val, y1_test = train_test_split(X1_val_test, y1_val_test, test_size=0.5, random_state=77)\n",
    "print(f\"\\nTraining data: {X1_train.shape},  labels: {y1_train.shape}\")\n",
    "print(f\"Validation data: {X1_val.shape},  labels: {y1_val.shape}\")\n",
    "print(f\"Testing data: {X1_test.shape},  labels: {y1_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45701a",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=.2, random_state=77)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=77)\n",
    "print(f\"\\nTraining data: {X_train.shape},  labels: {y_train.shape}\")\n",
    "print(f\"Validation data: {X_val.shape},  labels: {y_val.shape}\")\n",
    "print(f\"Testing data: {X_test.shape},  labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2208e00",
   "metadata": {},
   "source": [
    "Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask_path='/Users/mnoor/Desktop/FaceMaskProject/FaceMask/img/with_mask'\n",
    "No_mask='/Users/mnoor/Desktop/FaceMaskProject/FaceMask/img/without_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=[go.Pie(labels=['with_mask','without_mask'], \n",
    "        values=[len(os.listdir(Mask_path)),len(os.listdir(No_mask))])\n",
    "    ])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeff2e1",
   "metadata": {},
   "source": [
    "Distribution of the target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_set(data, labels, classes):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(10):\n",
    "        plt.subplot(5, 5, (i+1))\n",
    "        random_val = np.random.randint(low=0, high=len(data))\n",
    "        img = data[random_val]\n",
    "        plt.imshow(img)\n",
    "        plt.axis(False)\n",
    "        plt.title(classes[np.argmax(labels[random_val])])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_set(data=X_train, labels=y_train, classes=CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf19eb2",
   "metadata": {},
   "source": [
    "Model Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96003ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from keras.applications.vgg19 import VGG19  \n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Activation, Dropout, Flatten,InputLayer\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import mobilenet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de9dc5",
   "metadata": {},
   "source": [
    "MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ff497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape=(128,128,3)) \n",
    " \n",
    "for layer in model_3.layers:\n",
    "    layer.trainable = False    \n",
    "\n",
    "x = model_3.output\n",
    "x = Flatten()(x) \n",
    "x = Dense(100, activation='relu')(x) \n",
    "x = Dense(50, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x) \n",
    "\n",
    "model_3 = Model(inputs=model_3.input, outputs=predictions)\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train, y_train, validation_data=(X_val,y_val),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a7623",
   "metadata": {},
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68eb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))  \n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in model_6.layers:\n",
    "    layer.trainable = False  \n",
    "\n",
    "NN_transfer_19 = Sequential(\n",
    "                        [InputLayer(input_shape=(128,128,3)),model_6,\n",
    "                         Flatten(),  # should be fine , or add layers\n",
    "                         Dense(128, activation='relu'),\n",
    "                         Dense(64, activation='relu'),\n",
    "                         Dense(32, activation='relu'),   # 2 dense is must bcuz VGG16 model Conv2D twice and Maxpooling -> get a lot more features\n",
    "                         Dense(3, activation='softmax')]\n",
    "                       )\n",
    "\n",
    "NN_transfer_19.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'],)\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_V19 = NN_transfer_19.fit(X_train,y_train, validation_data=(X_val,y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = result_V19.history['accuracy']\n",
    "val_acc = result_V19.history['val_accuracy']\n",
    "\n",
    "loss = result_V19.history['loss']\n",
    "val_loss = result_V19.history['val_loss']\n",
    "\n",
    "epochs=10\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy', color = 'red') #, color = 'red')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy',color='blue')  # , color='blue')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss',color='red')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss',color='blue')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4833bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] saving mask detector model...\")\n",
    "model_6.save(\"Face-Mask-Detection-model_6.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a75ec",
   "metadata": {},
   "source": [
    "# Video detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55aa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9489b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the config file \n",
    "config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "\n",
    "# This is from the weight file \n",
    "frozen_model = 'frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cefd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance from model detection\n",
    "\n",
    "model = cv2.dnn_DetectionModel(frozen_model, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "file_name = 'labels.txt'\n",
    "with open(file_name, 'rt') as fpt:\n",
    "    class_labels = fpt.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setInputSize(320,320)\n",
    "# Note: 255/2 = 127.5\n",
    "model.setInputScale(1.0/127.5)\n",
    "\n",
    "model.setInputMean((127.5,127.5,127.5))\n",
    "\n",
    "model.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record any vidoe and add it here for a demo to the students \n",
    "import cv2\n",
    "#cap = cv2.VideoCapture('videos/car_traffic.mp4')\n",
    "cap = cv2.VideoCapture('/Users/mnoor/Desktop/FaceMaskProject/Video/Video1.mp4')\n",
    "\n",
    "# Check if video is open correclty \n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "if not cap.isOpened():\n",
    "    raise IOError('Cannot Open Video File')\n",
    "    \n",
    "# Text font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Font scale\n",
    "fontScale = 2 \n",
    "# Box color\n",
    "box_color = (255, 0, 0)\n",
    "# Teaxt color\n",
    "text_color = (0, 255, 0)\n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "   \n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    index, confidence, bbox = model.detect(frame)\n",
    "    \n",
    "    print(index)\n",
    "    if(len(index) !=0):\n",
    "        for index, conf, box in zip(index.flatten(), confidence.flatten(), bbox):\n",
    "            if(index <=2):\n",
    "                cv2.rectangle(frame, box, (255,0,0), 2)\n",
    "                cv2.putText(frame, class_labels[index-1],(box[0]+10, box[1]+40), font, fontScale = fontScale, color = text_color, thickness = thickness)\n",
    "\n",
    "    cv2.imshow('Object Detection Demo', frame)\n",
    "    \n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f818aa2",
   "metadata": {},
   "source": [
    "# LIVE Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential([\n",
    "    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(100, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"/Users/mnoor/Desktop/FaceMaskProject/FaceMask/train\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72280b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DIR = \"/Users/mnoor/Desktop/FaceMaskProject/FaceMask/test\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))\n",
    "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "model=load_model(\"model2-010.model\")\n",
    "\n",
    "labels_dict={0:'without mask',1:'mask'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}\n",
    "\n",
    "size = 4\n",
    "webcam = cv2.VideoCapture(0) #Use camera 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736dfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the xml file\n",
    "classifier = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    (rval, im) = webcam.read()\n",
    "    im=cv2.flip(im,1,1)\n",
    "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
    "    faces = classifier.detectMultiScale(mini)\n",
    "    for f in faces: \n",
    "        (x, y, w, h) = [v * size for v in f]\n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        resized=cv2.resize(face_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1) \n",
    "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "    cv2.imshow('LIVE',im)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27: #The Esc key \n",
    "        break\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94919696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
